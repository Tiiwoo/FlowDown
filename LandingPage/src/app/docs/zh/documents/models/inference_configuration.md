# 推理配置

集中管理模型的上下文长度、温度/采样、Reasoning/Thinking 开关与预算。所有设置均按“模型档案”生效，修改后即时应用并随 iCloud / 备份同步。

## 配置入口

1. 前往 **设置 → 模型**，选择目标档案。
2. 在 **推理** 与 **网络（可选）** 区域调整参数，完成后保存。

## 基础参数

- **上下文长度**：决定模型可保留的历史与附件。预估超限时，会优先裁剪最早的非系统消息；无法再裁剪时会终止请求。常用预设：4k/8k/16k/32k/64k/100k/200k/1M/Infinity。
- **创造力（温度）**：高温度输出更发散，低温度更稳定。常规问答建议 0.5–0.75；代码/事实类 0–0.25。可直接选择预设（例如 Humankind、Precise）。
- **采样参数**：在 JSON/编辑器视图添加 `top_p`、`top_k`、`presence_penalty`、`frequency_penalty`、`repetition_penalty` 等，小步调整、逐项验证。

## 高级推理（Reasoning / Thinking）

适用于支持链式思考的服务商（需在请求体加入特定键）。

1. 打开 **附加请求体**，选择右上角菜单 **推理参数**。
2. 插入对应键：`reasoning` / `enable_thinking` / `thinking_mode` / `thinking`。
3. 选择 **推理预算** 预设（512/1024/4096/8192 token）。浮望会根据键名写入 `reasoning.max_tokens` 或 `thinking_budget`。
4. 如需更多控制，可在同一 JSON 对象中追加服务商要求的开关或追踪字段。

> 若存在多个推理键，编辑器会提示冲突，请保留一组。

## 上下文与工具的关系

- 计入上下文的内容：系统提示词（全局/会话）、近期消息、附件文本与媒体、搜索结果、工具定义与输出、推理字段。
- 媒体估算：图片约 512 token，音频约 1024 token。超限时会提示“部分消息已被移除”。
- 控制占用：减少搜索结果页数或 MCP 返回条目，必要时压缩对话或将事实写入记忆。

## 服务商与网络高级配置

- **Header/Body**：在 **请求头** 与 **附加请求体** 中写入鉴权、租户 ID、推理开关或采样参数。请保持合法 JSON。
- **内容格式**：`chatCompletions` 与 `responses` 必须与端点一致，否则会调用失败。
- **能力声明**：按真实支持勾选工具/视觉/音频/开发者角色，以便界面正确暴露开关并控制附件回传。

## 相关链接

- 如果需要编辑端点、Header/Body 结构，请参阅 [云端模型设置](./cloud_models_setup.md#进阶自定义企业配置)。
- 如需压缩对话或管理系统提示词，参阅 [系统提示词](../configuration/system_prompts.md) 与 [记忆管理](../settings/memory_management.md)。***

