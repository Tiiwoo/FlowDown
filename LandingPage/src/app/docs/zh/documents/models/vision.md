# 模型视觉

## 概述

浮望支持通过本地 MLX 或云端视觉模型完成图像理解，并在需要时自动为纯文本模型生成描述、OCR 与二维码结果。默认会在发送前将图片压缩至约 1024 像素并移除 EXIF 信息（可在 **设置 → 编辑器 → 压缩图片** 调整）。

![图片压缩设置](../../../res/screenshots/imgs/flowdown-chat-compression-feature-ui.png)

## 快速上手

1. 点击输入框旁的 **＋** 按钮，或将文件直接拖入/粘贴到输入框。
2. 在 iOS/iPadOS 可拍照、选取相册或文件；在 macOS 可选择任意受系统支持的文件。
3. 发送问题或指令，等待模型返回图像分析结果。

添加后的缩略图会显示在输入框上方，点击或悬停可预览、重命名或移除附件。

![从输入框添加图片](../../../res/screenshots/imgs/mobile-chat-context-menu-functions.png)

## 配置清单

- **启用视觉能力**：在 **设置 → 模型**（本地）或模型编辑页（云端）打开「视觉」能力。未支持视觉的模型强行开启会报错。
- **辅助视觉模型**：路径 **设置 → 推理 → 视觉评估 → 辅助视觉模型**。用于当前对话模型不支持视觉、或需要文字备份时生成描述/OCR/二维码结果。
- **尝试跳过识别**：路径 **设置 → 推理 → 视觉评估**，默认开启。若当前模型具备视觉，开启后直接发送原图；若需要 OCR 或可能切换到纯文本模型，建议关闭。
- **压缩图片**：路径 **设置 → 编辑器 → 压缩图片**，默认开启以缩短上传时间并去除隐私信息。

![能力配置](../../../res/screenshots/imgs/ai-model-capability-configuration.png)
![视觉推理配置](../../../res/screenshots/imgs/visual-inference-model-configuration.png)

## 工作机制

### 双通路

- **视觉模型**：直接接收图片数据，并同时附带生成的描述（如有）。
- **非视觉模型**：调用辅助视觉模型生成文字表示，再将文字发送给主模型。

### 预处理触发

- 当图片没有手动说明，且满足以下任一条件时触发预处理：
  - 当前对话模型不支持视觉；
  - 已关闭「尝试跳过识别」。
- 若当前模型支持视觉且开启了「尝试跳过识别」，则跳过预处理，直接发送原图。

### 处理步骤

- 生成场景描述
- 多语言 OCR 文本提取
- 二维码检测与解码

处理结果会写入附件的文字表示并持久化（非临时消息），图片始终会压缩并移除 EXIF 信息。若未配置具备 Vision 的辅助模型且当前模型为纯文本，图片会被跳过。

### 发送到对话

- **视觉模型**：发送原图及文字描述。
- **文本模型**：仅发送文字表示；若为空则跳过该附件。

## 提示与验证

- 指令尽量明确，例如“请用要点总结这块白板”、“比较这两张截图”或“把表格转成 CSV”。
- 可以在提示词里引用文件名，如“在 invoice.png 中付款截止日期是多少？”。
- 在消息菜单选择 **原始数据** 可核对 `[Image Description]`、`[Image Optical Character Recognition Result]`、`[QRCode Recognition]` 等内容块。
- 若结果不理想，可要求模型重新审视附件或补充上下文后再发。
- 若不希望长期保存附件，可在消息菜单中删除。

![包含附件的渲染效果](../../../res/screenshots/imgs/flowdown-ai-content-rendering-process.png)
